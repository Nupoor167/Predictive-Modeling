{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c7a34c-dbc4-4e6e-a6dd-0d51cf04d08e",
   "metadata": {},
   "source": [
    "## Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd9e5fe-89d3-452e-a195-1ee635b2cff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#vix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#load StatsModel API\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac2d6d8-c281-4099-9c8a-939eb70aa048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/notices.json HTTP/1.1\" 404 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/notices.json HTTP/1.1\" 404 None\n",
      "done\n",
      "Collecting package metadata (current_repodata.json): / DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "- DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/current_repodata.json HTTP/1.1\" 200 None\n",
      "\\ DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/osx-arm64/current_repodata.json HTTP/1.1\" 304 0\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.2\n",
      "  latest version: 24.1.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.1.2\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/nupoor/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - plotly\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    plotly-5.19.0              |  py311hb6e6a13_0         6.3 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.3 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  plotly                              5.9.0-py311hca03da5_0 --> 5.19.0-py311hb6e6a13_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "plotly-5.19.0        | 6.3 MB    |                                       |   0% DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/plotly-5.19.0-py311hb6e6a13_0.conda HTTP/1.1\" 200 6624618\n",
      "                                                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99da231-2203-4a09-ae08-8b5a7cb12672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79a2e1-1d82-4fa7-b206-0256e5b720b8",
   "metadata": {},
   "source": [
    "### 3. We now review k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb13b28-3e33-4f74-a9f5-b496b8863382",
   "metadata": {},
   "source": [
    "#### (a) Explain how k-fold cross-validation is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8c16f-7d6a-435b-9c96-8b63e5b8c4b8",
   "metadata": {},
   "source": [
    "* K-fold cross-validation is a method for assessing the performance of a machine learning model and mitigating overfitting by iteratively splitting the dataset into k equally sized subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc0226-e837-4c1e-860e-b88e95e2b348",
   "metadata": {},
   "source": [
    "#### (b) What are the advantages and disadvantages of k-fold cross-validation relative to:\n",
    "####  i. The validation set approach?\n",
    "* Advantages of k-fold cross-validation:\n",
    "Better utilization of data: K-fold cross-validation utilizes the entire dataset for both training and validation, providing a more comprehensive assessment of the model's performance.\n",
    "Robust performance estimate: By averaging performance metrics across multiple folds, k-fold cross-validation produces a more reliable estimate of the model's generalization ability.\n",
    "Reduced variance: The variance of the performance estimate is lower as it's averaged over multiple validation sets.\n",
    "\n",
    "* Disadvantages of k-fold cross-validation relative to the validation set approach:\n",
    "Computational overhead: K-fold cross-validation requires training and evaluating the model k times, which can be computationally expensive, especially for large datasets or complex models.\n",
    "Increased training time: Splitting the dataset into multiple folds and training the model repeatedly can prolong the training process.\n",
    "####  ii. LOOCV?\n",
    "* Advantages of k-fold cross-validation:\n",
    "Reduced bias: K-fold cross-validation typically has lower bias compared to LOOCV because it averages over multiple validation sets, reducing the impact of a single data point on the model's evaluation.\n",
    "Less sensitive to outliers: K-fold cross-validation is less affected by outliers compared to LOOCV, as it aggregates results over multiple folds.\n",
    "\n",
    "* Disadvantages of k-fold cross-validation relative to LOOCV:\n",
    "Higher variance: K-fold cross-validation may have higher variance compared to LOOCV, especially when the dataset is small, as it involves random partitioning of data into folds.\n",
    "Computational complexity: Although LOOCV involves training the model only once per data point, k-fold cross-validation requires training the model multiple times, leading to increased computational complexity, especially for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad01ae-eef4-45d9-a5e3-8386f127a60f",
   "metadata": {},
   "source": [
    "### 5. In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.\n",
    "#### (a) Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c28c51c-121f-4c43-aee1-4d8654eb0ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default= pd.read_csv('Default.csv', na_values='?').dropna()\n",
    "\n",
    "# Display the first few rows\n",
    "default.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6087b057-2245-468a-ae85-2f4715fcca74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      default student      balance        income\n",
       "0         No      No   729.526495  44361.625074\n",
       "1         No     Yes   817.180407  12106.134700\n",
       "2         No      No  1073.549164  31767.138947\n",
       "3         No      No   529.250605  35704.493935\n",
       "4         No      No   785.655883  38463.495879\n",
       "...      ...     ...          ...           ...\n",
       "9995      No      No   711.555020  52992.378914\n",
       "9996      No      No   757.962918  19660.721768\n",
       "9997      No      No   845.411989  58636.156984\n",
       "9998      No      No  1569.009053  36669.112365\n",
       "9999      No     Yes   200.922183  16862.952321\n",
       "\n",
       "[10000 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b47939-6bed-4668-9d5c-5fbc07914004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   default  10000 non-null  int64\n",
      " 1   student  10000 non-null  int64\n",
      " 2   balance  10000 non-null  int64\n",
      " 3   income   10000 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 312.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'default' and 'student' columns contain categorical values ('yes' or 'no')\n",
    "\n",
    "# Mapping 'yes' to 1 and 'no' to 0\n",
    "default['default'] = default['default'].map({'Yes': 1, 'No': 0})\n",
    "default['student'] = default['student'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Or using replace method\n",
    "default['default'] = default['default'].replace({'Yes': 1, 'No': 0})\n",
    "default['student'] = default['student'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "default['default'] = default['default'].astype('int64')\n",
    "default['student'] = default['student'].astype('int64')\n",
    "default['income'] = default['income'].astype('int64')\n",
    "default['income'] = default['income'].astype('int64')\n",
    "default.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37827f02-7b84-4301-8657-d01a8698c461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    0\n",
       "9998    0\n",
       "9999    0\n",
       "Name: default, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert the 'default' column to int64\n",
    "endog = Default.astype(\"int64\")\n",
    "\n",
    "endog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe2ea012-88dc-441e-b23b-9e5aa5fe268c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>729</td>\n",
       "      <td>44361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>817</td>\n",
       "      <td>12106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073</td>\n",
       "      <td>31767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>35704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>785</td>\n",
       "      <td>38463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>711</td>\n",
       "      <td>52992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>19660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>845</td>\n",
       "      <td>58636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1569</td>\n",
       "      <td>36669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>16862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  default  balance  income\n",
       "0       1.0        0      729   44361\n",
       "1       1.0        0      817   12106\n",
       "2       1.0        0     1073   31767\n",
       "3       1.0        0      529   35704\n",
       "4       1.0        0      785   38463\n",
       "...     ...      ...      ...     ...\n",
       "9995    1.0        0      711   52992\n",
       "9996    1.0        0      757   19660\n",
       "9997    1.0        0      845   58636\n",
       "9998    1.0        0     1569   36669\n",
       "9999    1.0        0      200   16862\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog = sm.add_constant(default.drop(columns=[\"student\"]))\n",
    "exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ee83335-ba8d-43f5-9956-a927b2749eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/Users/nupoor/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>default</td>     <th>  No. Observations:  </th>   <td> 10000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9996</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 07 Mar 2024</td> <th>  Pseudo R-squ.:     </th>   <td> 1.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:34:11</td>     <th>  Log-Likelihood:    </th> <td>-1.9824e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th>  <td> -1460.3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td> 0.000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>  -19.4157</td> <td> 2236.895</td> <td>   -0.009</td> <td> 0.993</td> <td>-4403.648</td> <td> 4364.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>default</th> <td>   45.1131</td> <td> 3337.179</td> <td>    0.014</td> <td> 0.989</td> <td>-6495.638</td> <td> 6585.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th> <td>   -0.0008</td> <td>    1.736</td> <td>   -0.000</td> <td> 1.000</td> <td>   -3.404</td> <td>    3.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>  <td>   -0.0001</td> <td>    0.073</td> <td>   -0.001</td> <td> 0.999</td> <td>   -0.143</td> <td>    0.143</td>\n",
       "</tr>\n",
       "</table><br/><br/>Complete Separation: The results show that there iscomplete separation or perfect prediction.<br/>In this case the Maximum Likelihood Estimator does not exist and the parameters<br/>are not identified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     default      & \\textbf{  No. Observations:  } &     10000    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      9996    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &         3    \\\\\n",
       "\\textbf{Date:}            & Thu, 07 Mar 2024 & \\textbf{  Pseudo R-squ.:     } &     1.000    \\\\\n",
       "\\textbf{Time:}            &     19:34:11     & \\textbf{  Log-Likelihood:    } & -1.9824e-06  \\\\\n",
       "\\textbf{converged:}       &      False       & \\textbf{  LL-Null:           } &    -1460.3   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &     0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}   &     -19.4157  &     2236.895     &    -0.009  &         0.993        &    -4403.648    &     4364.817     \\\\\n",
       "\\textbf{default} &      45.1131  &     3337.179     &     0.014  &         0.989        &    -6495.638    &     6585.865     \\\\\n",
       "\\textbf{balance} &      -0.0008  &        1.736     &    -0.000  &         1.000        &       -3.404    &        3.402     \\\\\n",
       "\\textbf{income}  &      -0.0001  &        0.073     &    -0.001  &         0.999        &       -0.143    &        0.143     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Complete Separation: The results show that there iscomplete separation or perfect prediction. \\newline\n",
       " In this case the Maximum Likelihood Estimator does not exist and the parameters \\newline\n",
       " are not identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                default   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9996\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 07 Mar 2024   Pseudo R-squ.:                   1.000\n",
       "Time:                        19:34:11   Log-Likelihood:            -1.9824e-06\n",
       "converged:                      False   LL-Null:                       -1460.3\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -19.4157   2236.895     -0.009      0.993   -4403.648    4364.817\n",
       "default       45.1131   3337.179      0.014      0.989   -6495.638    6585.865\n",
       "balance       -0.0008      1.736     -0.000      1.000      -3.404       3.402\n",
       "income        -0.0001      0.073     -0.001      0.999      -0.143       0.143\n",
       "==============================================================================\n",
       "\n",
       "Complete Separation: The results show that there iscomplete separation or perfect prediction.\n",
       "In this case the Maximum Likelihood Estimator does not exist and the parameters\n",
       "are not identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fit the logistic regression model\n",
    "logit_mod = sm.Logit(endog, exog)\n",
    "logit_result = logit_mod.fit()\n",
    "logit_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee2b46-8159-480c-9923-3cb2dd8c77a6",
   "metadata": {},
   "source": [
    "#### (b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "#### i. Split the sample set into a training set and a validation set.\n",
    "#### ii. Fit a multiple logistic regression model using only the training observations.\n",
    "#### iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "#### iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bcf3140-766d-4189-9f3e-869abd8fa74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027289082195555328"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize ,\n",
    "                         poly)\n",
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate , KFold , ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm\n",
    "\n",
    "\n",
    "random_seed=1\n",
    "default_train, default_valid = train_test_split(default,\n",
    "                                             test_size=5000, random_state=random_seed)\n",
    "\n",
    "dd = MS(['balance', 'income'])\n",
    "X_train = dd.fit_transform(default_train) \n",
    "y_train = default_train['default']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "\n",
    "X_valid = dd.transform(default_valid) \n",
    "y_valid = default_valid['default'] \n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6015bc-811c-4c63-9d92-79ea375855af",
   "metadata": {},
   "source": [
    "#### (c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c4cd528-7c87-4b19-b9b4-4b594a65e8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025981211117436117"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train, default_valid = train_test_split(default,\n",
    "                                             test_size=2000, random_state=random_seed)\n",
    "\n",
    "dd = MS(['balance', 'income'])\n",
    "X_train = dd.fit_transform(default_train) \n",
    "y_train = default_train['default']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "\n",
    "X_valid = dd.transform(default_valid) \n",
    "y_valid = default_valid['default'] \n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4015ba2d-40ca-437d-b3f7-36f79e83603b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026630463503038455"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train, default_valid = train_test_split(default,\n",
    "                                             test_size=3500, random_state=random_seed)\n",
    "\n",
    "dd = MS(['balance', 'income'])\n",
    "X_train = dd.fit_transform(default_train) \n",
    "y_train = default_train['default']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "\n",
    "X_valid = dd.transform(default_valid) \n",
    "y_valid = default_valid['default'] \n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ffe573e-f099-4a8b-9bf3-f948c4be7a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026646818484376566"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train, default_valid = train_test_split(default,\n",
    "                                             test_size=4000, random_state=random_seed)\n",
    "\n",
    "dd = MS(['balance', 'income'])\n",
    "X_train = dd.fit_transform(default_train) \n",
    "y_train = default_train['default']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "\n",
    "X_valid = dd.transform(default_valid) \n",
    "y_valid = default_valid['default'] \n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f407da-1a50-4fbd-8e73-d614a9039eae",
   "metadata": {},
   "source": [
    "* MSE is least in 2000(0.02598) as comapred to other tested sizes such as 5000, 3500, and 4000, underscores the importance of considering the trade-offs between model performance and computational efficiency. It also suggests that the model's predictive performance was optimal or most accurate when evaluated on datasets of this size. While larger test data sizes might theoretically provide a more robust evaluation of the model's generalization ability, the decrease in MSE with a test size of 2000 suggests that there might be a point of diminishing returns, where additional data beyond a certain threshold does not significantly improve predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d613d-30c4-438d-b8c3-57ddfe0f8b48",
   "metadata": {},
   "source": [
    "#### (d) Now consider a logistic regression model that predicts the prob- ability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the val- idation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f81afff-1adf-4f68-8888-c4e2a1f27ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729</td>\n",
       "      <td>44361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817</td>\n",
       "      <td>12106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073</td>\n",
       "      <td>31767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>35704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785</td>\n",
       "      <td>38463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>711</td>\n",
       "      <td>52992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>19660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>845</td>\n",
       "      <td>58636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1569</td>\n",
       "      <td>36669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>16862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      default  student  balance  income\n",
       "0           0        0      729   44361\n",
       "1           0        1      817   12106\n",
       "2           0        0     1073   31767\n",
       "3           0        0      529   35704\n",
       "4           0        0      785   38463\n",
       "...       ...      ...      ...     ...\n",
       "9995        0        0      711   52992\n",
       "9996        0        0      757   19660\n",
       "9997        0        0      845   58636\n",
       "9998        0        0     1569   36669\n",
       "9999        0        1      200   16862\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define endog and exog variables\n",
    "y = default['default']\n",
    "X = default[['balance', 'income', 'student']]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Convert the 'student' column into a dummy variable\n",
    "dummy_student = pd.get_dummies(default['student'], drop_first=True)\n",
    "\n",
    "# Concatenate the dummy variable with the independent variables\n",
    "X = pd.concat([X, dummy_student], axis=1)\n",
    "\n",
    "default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70e68ef2-4989-4165-af1e-771d9a68e43f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078581\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 07 Mar 2024   Pseudo R-squ.:                  0.4619\n",
      "Time:                        20:15:10   Log-Likelihood:                -785.81\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.389e-292\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.8658      0.492    -22.078      0.000     -11.830      -9.901\n",
      "balance        0.0057      0.000     24.737      0.000       0.005       0.006\n",
      "income      3.038e-06    8.2e-06      0.370      0.711    -1.3e-05    1.91e-05\n",
      "student       -0.3233   1.52e+07  -2.13e-08      1.000   -2.98e+07    2.98e+07\n",
      "1             -0.3233   1.52e+07  -2.13e-08      1.000   -2.98e+07    2.98e+07\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# Fit the logistic regression model\n",
    "logit_mod = sm.Logit(y, X)\n",
    "logit_result = logit_mod.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(logit_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6443617-ccbe-46b5-8ede-3199ccaf3718",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025985810872869025"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train, default_valid = train_test_split(default,\n",
    "                                             test_size=2000, random_state=random_seed)\n",
    "\n",
    "dd = MS(['balance', 'income', 'student'])\n",
    "X_train = dd.fit_transform(default_train) \n",
    "y_train = default_train['default']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "\n",
    "X_valid = dd.transform(default_valid) \n",
    "y_valid = default_valid['default'] \n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c354856-2305-4281-ba10-0baf9ba24f75",
   "metadata": {},
   "source": [
    "### - Creating a dummy variable does not reduce the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48576a-8d7a-4b0c-a05c-92a15a98ede0",
   "metadata": {},
   "source": [
    "### 6. We continue to consider the use of a logistic regression model to predict the probability of default using income and balance on the Default data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coeffi- cients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the sm.GLM() function. Do not forget to set a random seed before beginning your analysis.\n",
    "#### (a) Using the summarize() and sm.GLM() functions, determine the estimated standard errors for the coefficients associated with income and balance in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0f5366d-40a3-4ce8-88ac-0bd35463b52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9997\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -789.52\n",
      "Date:                Thu, 07 Mar 2024   Deviance:                       1579.0\n",
      "Time:                        20:21:48   Pearson chi2:                 6.95e+03\n",
      "No. Iterations:                     9   Pseudo R-squ. (CS):             0.1256\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -11.5370      0.435    -26.544      0.000     -12.389     -10.685\n",
      "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
      "balance        0.0056      0.000     24.836      0.000       0.005       0.006\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed\n",
    "random_seed = 42\n",
    "\n",
    "# Define endog and exog variables\n",
    "endog = default['default']\n",
    "exog = default[['income', 'balance']]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.GLM(endog, exog, family=sm.families.Binomial())\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10552fda-ecbb-4a67-995e-cc39bc58bbcc",
   "metadata": {},
   "source": [
    "#### (b) Write a function, boot_fn(), that takes as input the Default data set as well as an index of the observations, and that outputs the coefficient estimates for income and balance in the multiple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4ecde6a8-98f5-4cae-afbf-cfd96a51eb60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept         NaN\n",
      "income       0.000005\n",
      "balance      0.000227\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def boot_fn(data, index, formula=None):\n",
    "    if formula:\n",
    "        model = sm.GLM.from_formula(formula, family=sm.families.Binomial(), data=data.iloc[index])\n",
    "    else:\n",
    "        endog = data['default'].iloc[index]\n",
    "        exog = data[['income', 'balance']].iloc[index]\n",
    "        exog = sm.add_constant(exog)\n",
    "        model = sm.GLM(endog, exog, family=sm.families.Binomial())\n",
    "    result = model.fit()\n",
    "    return result.params\n",
    "\n",
    "def bootstrap(data, n_iterations=1000, formula=None):\n",
    "    bootstrap_coefs = []\n",
    "    for _ in range(n_iterations):\n",
    "        index = np.random.choice(data.index, size=len(data), replace=True)\n",
    "        bootstrap_coefs.append(boot_fn(data, index, formula=formula))\n",
    "\n",
    "    bootstrap_coefs = pd.DataFrame(bootstrap_coefs, columns=['Intercept', 'income', 'balance'])\n",
    "    bootstrap_se = bootstrap_coefs.std()\n",
    "    return bootstrap_se  # Add return statement here\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'default' is your DataFrame\n",
    "bootstrap_se = bootstrap(default)\n",
    "print(bootstrap_se)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8d2e7-21fd-4417-9c96-ed64c21abc73",
   "metadata": {},
   "source": [
    "#### as this does not work well. Trying the below one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "552f7302-b8a4-429a-a167-2862be561026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.429394\n",
       "income       0.000005\n",
       "balance      0.000229\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boot_fn(default, index):\n",
    "    model = sm.GLM.from_formula('default ~ income + balance', family=sm.families.Binomial(), data=default.iloc[index])\n",
    "    result = model.fit()\n",
    "    return result.params\n",
    "\n",
    "n_iterations = 1000\n",
    "bootstrap_coefs = []\n",
    "for _ in range(n_iterations):\n",
    "    index = np.random.choice(default.index, size=len(default), replace=True)\n",
    "    bootstrap_coefs.append(boot_fn(default, index))\n",
    "\n",
    "bootstrap_coefs = pd.DataFrame(bootstrap_coefs, columns=['Intercept', 'income', 'balance'])\n",
    "# Calculate standard errors\n",
    "bootstrap_se = bootstrap_coefs.std()\n",
    "bootstrap_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cc267e95-9f73-487c-b2dc-32a3e7d63a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income    -0.000129\n",
       "balance    0.000477\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boot_fn(default, index):\n",
    "    # Select subset of data based on the given index\n",
    "    subset = default.iloc[index]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X_boot = subset[['income', 'balance']]\n",
    "    y_boot = subset['default']\n",
    "    \n",
    "    # Fit logistic regression model\n",
    "    model_boot = sm.Logit(y_boot, X_boot)\n",
    "    result_boot = model_boot.fit(disp=0)\n",
    "    \n",
    "    # Return coefficient estimates for 'income' and 'balance'\n",
    "    return result_boot.params\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'default' is your dataset and 'index' is a list of indices for the subset of data\n",
    "coeff = boot_fn(default, index)\n",
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed071b-e43c-48db-997c-35743b86ec6b",
   "metadata": {},
   "source": [
    "#### (c) Following the bootstrap example in the lab, use your boot_fn() function to estimate the standard errors of the logistic regression coefficients for income and balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c70b0de7-7f75-49c8-8956-7072eb74b5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error (alpha): 0.00033958238300135443\n"
     ]
    }
   ],
   "source": [
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['income', 'balance']].iloc[idx], rowvar=False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) / (cov_[0,0] + cov_[1,1] - 2*cov_[0,1]))\n",
    "\n",
    "def boot_SE(func, D, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)\n",
    "\n",
    "# Assuming 'default' is your dataset with predictor variables 'income', 'balance', 'student', and target variable 'default'\n",
    "alpha_SE = boot_SE(alpha_func, default, B=1000, seed=0)\n",
    "print(\"Standard Error (alpha):\", alpha_SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4b6a2-f576-45b4-b13c-823931d4a88b",
   "metadata": {},
   "source": [
    "#### (d) Comment on the estimated standard errors obtained using the sm.GLM() function and using the bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58ed0a-3a56-4701-86d4-d94265a0ca6a",
   "metadata": {},
   "source": [
    "* The standard errors obtained viz; income(-0.000129), balance(0.000477) and overall standard error(0.00033958238300135443) from the bootstrap tend to provide more robust estimates of the variability of the coefficient estimates compared to those obtained from the sm.GLM() function. Bootstrap resampling captures the variability in the data more accurately, making it a valuable tool for assessing the uncertainty of parameter estimates when analytical methods might not fully account for all sources of variability.\n",
    "\n",
    "* Tried both sm.glm and logit functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51931c6-356a-4059-804d-c5e9a191d1bb",
   "metadata": {},
   "source": [
    "### 9. We will now consider the Boston housing data set, from the ISLP library.\n",
    "#### (a) Based on this data set, provide an estimate for the population mean of medv. Call this estimate μˆ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29da1c14-8809-477f-87da-952e710aa1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean of medv (μˆ): 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "# Load the Boston dataset\n",
    "boston_file = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "boston = pd.read_csv(boston_file)\n",
    "\n",
    "\n",
    "mu_hat = boston['medv'].mean()\n",
    "\n",
    "print(\"Estimated mean of medv (μˆ):\", mu_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a31ece18-3d6b-44c3-8f1f-15a881f480c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75894e-6120-4140-af22-885c32c1351c",
   "metadata": {},
   "source": [
    "#### (b) Provide an estimate of the standard error of μˆ. Interpret this result.\n",
    "#### Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3105800b-f292-4b19-86f8-7b01a907415b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error of μˆ: 0.4088611474975351\n"
     ]
    }
   ],
   "source": [
    "sample_std = np.std(boston['medv'], ddof=1)\n",
    "\n",
    "# Calculate the number of observations\n",
    "n = len(boston['medv'])\n",
    "\n",
    "# Calculate the standard error of the sample mean\n",
    "standard_error_mu_hat = sample_std / np.sqrt(n)\n",
    "\n",
    "print(\"Standard error of μˆ:\", standard_error_mu_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965e9a0-288c-4bf1-b3cd-881e76daafa2",
   "metadata": {},
   "source": [
    "#### (c) Now estimate the standard error of μˆ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c9a2800-4245-4b9c-88d3-4db8905953f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error of μˆ using bootstrap: 0.4023244298640598\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate sample mean\n",
    "def sample_mean(boston):\n",
    "    return np.mean(boston)\n",
    "\n",
    "# Define function for bootstrapping\n",
    "def bootstrap(boston, func, n_iterations=1000):\n",
    "    sample_means = []\n",
    "    for _ in range(n_iterations):\n",
    "        # Resample data with replacement\n",
    "        resampled_data = np.random.choice(boston, size=len(boston), replace=True)\n",
    "        # Calculate sample mean\n",
    "        sample_means.append(func(resampled_data))\n",
    "    return np.std(sample_means)\n",
    "\n",
    "# Calculate standard error of μˆ using bootstrap\n",
    "bootstrap_se = bootstrap(boston['medv'], sample_mean)\n",
    "\n",
    "print(\"Standard error of μˆ using bootstrap:\", bootstrap_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93445643-fc00-4184-858a-7be1439ce4c3",
   "metadata": {},
   "source": [
    "- The standard error using bootstrap is slightly lower than without bootstrap method. The slightly lower standard error obtained with the bootstrap method suggests that resampling from the dataset helps to capture the variability more accurately, resulting in a more precise estimate of the standard error. This improvement in precision can be attributed to the bootstrap's ability to account for the inherent randomness in the dataset and provide a robust estimate of the standard error without relying on assumptions about the underlying distribution. It is more reliable and less susceptible to sampling variability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7bbf1-347c-4e42-98e0-5139db611aa6",
   "metadata": {},
   "source": [
    "#### (d) Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained by using Boston['medv'].std() and the two standard error rule (3.9).\n",
    "#### Hint: You can approximate a 95 % confidence interval using the formula [μˆ − 2SE(μˆ), μˆ + 2SE(μˆ)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e56f8fa0-1715-4f86-bfaf-f86164198fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.49612750938295, 22.569485138838402)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_se = boot_SE(lambda D, idx: np.mean(D.loc[idx, 'medv']), boston, B=1000, seed=0)\n",
    "\n",
    "# Compute the standard error of the mean (SEM)\n",
    "SEM = bootstrap_se / np.sqrt(len(boston))\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = (np.mean(boston['medv']) - 2 * SEM, np.mean(boston['medv']) + 2 * SEM)\n",
    "\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040b583-4e64-401c-9627-3392994b7d00",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (e) Based on this data set, provide an estimate, μˆmed, for the median value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf2a5b8e-4a76-42ca-b788-14d76f19482c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_medv = np.median(boston['medv'])\n",
    "\n",
    "median_medv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22543a6f-a8da-4873-aaff-9a070979c5e5",
   "metadata": {},
   "source": [
    "#### (f) We now would like to estimate the standard error of μˆmed. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "536b9b94-8de5-4c3e-b592-38f9ad86023c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36963108248243537"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bootstrap_median(boston, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    medians = []\n",
    "    n = len(boston)\n",
    "    \n",
    "    for _ in range(B):\n",
    "        # Generate bootstrap sample by resampling with replacement\n",
    "        bootstrap_sample = rng.choice(boston, size=n, replace=True)\n",
    "        # Calculate median of bootstrap sample\n",
    "        median = np.median(bootstrap_sample)\n",
    "        medians.append(median)\n",
    "    \n",
    "    # Compute standard error of the median\n",
    "    std_error = np.std(medians, ddof=1)\n",
    "    return std_error\n",
    "\n",
    "# Assuming 'boston' is your DataFrame and 'CMEDV' is the column containing median values\n",
    "std_error_median = bootstrap_median(boston['medv'])\n",
    "\n",
    "std_error_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c6025a-9c43-4f20-8df9-521b67cf95e1",
   "metadata": {},
   "source": [
    "- The standard error of the median, estimated using the bootstrap method, is approximately 0.3696. This value represents the variability or uncertainty associated with our estimate of the median value of medv in the population. A lower standard error indicates higher precision in our estimate, meaning that our median estimate is likely to be closer to the true population median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f76ed0-fc5c-4aa0-a0d6-e8520760d7e5",
   "metadata": {},
   "source": [
    "#### (g) Based on this data set, provide an estimate for the tenth per- centile of medv in Boston census tracts. Call this quantity μˆ0.1. (You can use the np.percentile() function.) np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1b84df5-298a-4e02-932a-e988eefc4b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenth_percentile = np.percentile(boston['medv'], 10)\n",
    "tenth_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64873505-c09f-4015-8b1f-5a04bdeffe2c",
   "metadata": {},
   "source": [
    "#### (h) Use the bootstrap to estimate the standard error of μˆ0.1. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e98142e3-3e8c-4969-84bd-6c9a66fd44a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5037060251374404"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tenth_percentile_func(D, idx):\n",
    "    return np.percentile(D.loc[idx, 'medv'], 10)\n",
    "\n",
    "# Define a function to calculate the standard error of the tenth percentile using the bootstrap method\n",
    "def boot_SE_tenth_percentile(func, D, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    percentile_values = []\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, n, replace=True)\n",
    "        percentile_value = func(D, idx)\n",
    "        percentile_values.append(percentile_value)\n",
    "    return np.std(percentile_values, ddof=1)\n",
    "\n",
    "# Estimate the standard error of μˆ0.1 using the bootstrap method\n",
    "bootstrap_se_tenth_percentile = boot_SE_tenth_percentile(tenth_percentile_func, boston, B=1000, seed=0)\n",
    "bootstrap_se_tenth_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6277c2-d2d5-494e-85d6-3429eb9a3676",
   "metadata": {},
   "source": [
    "- The error is highest that is 0.5037 as compared to Standard error of μˆ: 0.4088, Standard error of μˆ using bootstrap: 0.4023 and std_error_median 0.36963108248243537 indicating more variability in the estimate of the tenth percentile compared to the mean. It may not necessarily outperform direct calculations using percentile functions in terms of precision. However, it still offers a robust and flexible approach, especially when exact formulas for standard errors are not readily available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
